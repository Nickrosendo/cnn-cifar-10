{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e123e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19941525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "5.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "12.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "25.0%"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(root='data/', download=True, transform=ToTensor())\n",
    "test_dataset = CIFAR10(root='data/', train=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#size of training data\n",
    "dataset_size = len(dataset)\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3559ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of test data\n",
    "test_dataset_size = len(test_dataset)\n",
    "test_dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c461b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of classes in the data set\n",
    "classes = dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img, label = dataset[0]\n",
    "print(img.shape, label)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e649260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_example(img, label):\n",
    "    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(*dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_example(*dataset[1099])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training & Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9620a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 5000\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b8d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution operation on a 1 channel image with a 3x3 kernel.\n",
    "def apply_kernel(image, kernel):\n",
    "    ri, ci = image.shape       # image dimensions\n",
    "    rk, ck = kernel.shape      # kernel dimensions\n",
    "    ro, co = ri-rk+1, ci-ck+1  # output dimensions\n",
    "    output = torch.zeros([ro, co])\n",
    "    for i in range(ro): \n",
    "        for j in range(co):\n",
    "            output[i,j] = torch.sum(image[i:i+rk,j:j+ck] * kernel)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = torch.tensor([\n",
    "    [3, 3, 2, 1, 0], \n",
    "    [0, 0, 1, 3, 1], \n",
    "    [3, 1, 2, 2, 3], \n",
    "    [2, 0, 0, 2, 2], \n",
    "    [2, 0, 0, 0, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "sample_kernel = torch.tensor([\n",
    "    [0, 1, 2], \n",
    "    [2, 2, 0], \n",
    "    [0, 1, 2]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "apply_kernel(sample_image, sample_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8104dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dbcf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),\n",
    "    nn.MaxPool2d(2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cab3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dl:\n",
    "    print('images.shape:', images.shape)\n",
    "    out = simple_model(images)\n",
    "    print('out.shape:', out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396eeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model by extending an ImageClassificationBase class with helper methods for training & validation.\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a98799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe10d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10CnnModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063040a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dl:\n",
    "    print('images.shape:', images.shape)\n",
    "    out = model(images)\n",
    "    print('out.shape:', out.shape)\n",
    "    print('out[0]:', out[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc20fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00417547",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f66df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ecd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76104d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae684cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(Cifar10CnnModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3047dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters for training model\n",
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd89d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53366e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57951f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13088848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "    return dataset.classes[preds[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447feea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[1002]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[6153]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2062579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6210dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a05341",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cifar10-cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb00363",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = to_device(Cifar10CnnModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_state_dict(torch.load('cifar10-cnn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model2, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[6152]\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[6152]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b196ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[615]\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388fc004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
